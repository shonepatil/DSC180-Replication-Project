{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.features.build_features import load_data\n",
    "from src.model.train import train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preface\n",
    "\n",
    "This dataset involves predicting what category scientific papers fall into. There is a network of papers as well as the words used in the title."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CORA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading musae_ENGB_ dataset...\n",
      "Graph Info:\n",
      " Name: G\n",
      "Type: Graph\n",
      "Number of nodes: 7126\n",
      "Number of edges: 35324\n",
      "Average degree:   9.9141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s3patil/DSC 180/DSC180-Replication-Project/src/model/utils.py:13: UserWarning: torch.eig is deprecated in favor of torch.linalg.eig and will be removed in a future PyTorch release.\n",
      "torch.linalg.eig returns complex tensors of dtype cfloat or cdouble rather than real tensors mimicking complex tensors.\n",
      "L, _ = torch.eig(A)\n",
      "should be replaced with\n",
      "L_complex = torch.linalg.eigvals(A)\n",
      "and\n",
      "L, V = torch.eig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L_complex, V_complex = torch.linalg.eig(A) (Triggered internally at  /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2897.)\n",
      "  evals, evecs = torch.eig (m, eigenvectors = True)  # get eigendecomposition\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of A:  torch.Size([7126, 7126])\n",
      "\n",
      "Shape of X:  torch.Size([7126, 3])\n",
      "\n",
      "Adjacency Matrix (A):\n",
      " tensor([[0.1250, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0500, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.2500, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0476, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3333]])\n",
      "\n",
      "Node Features Matrix (X):\n",
      " tensor([[-0.0937, -0.0620, -0.2387],\n",
      "        [ 0.1469, -0.0640, -0.2387],\n",
      "        [-1.5768, -0.0495, -0.2387],\n",
      "        ...,\n",
      "        [-0.1517, -0.0639, -0.2387],\n",
      "        [ 0.7370, -0.0631, -0.2387],\n",
      "        [ 0.3846, -0.0640, -0.2387]])\n"
     ]
    }
   ],
   "source": [
    "A, X, y, idx_train, idx_val, idx_test = load_data(\"../data/twitch/\", \"musae_ENGB_\", 1000, 2000, 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCN (features only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0010 loss_train: 0.7175 acc_train: 0.5000 loss_val: 0.7030 acc_val: 0.5045 time: 0.0039s\n",
      "Epoch: 0020 loss_train: 0.7094 acc_train: 0.4930 loss_val: 0.6988 acc_val: 0.5055 time: 0.0035s\n",
      "Epoch: 0030 loss_train: 0.6974 acc_train: 0.5360 loss_val: 0.6964 acc_val: 0.5120 time: 0.0033s\n",
      "Epoch: 0040 loss_train: 0.7062 acc_train: 0.5270 loss_val: 0.6947 acc_val: 0.5185 time: 0.0031s\n",
      "Epoch: 0050 loss_train: 0.7014 acc_train: 0.5280 loss_val: 0.6935 acc_val: 0.5260 time: 0.0032s\n",
      "Epoch: 0060 loss_train: 0.7000 acc_train: 0.5290 loss_val: 0.6925 acc_val: 0.5365 time: 0.0051s\n",
      "Epoch: 0070 loss_train: 0.7043 acc_train: 0.5260 loss_val: 0.6919 acc_val: 0.5415 time: 0.0046s\n",
      "Epoch: 0080 loss_train: 0.7043 acc_train: 0.5140 loss_val: 0.6914 acc_val: 0.5440 time: 0.0037s\n",
      "Epoch: 0090 loss_train: 0.7029 acc_train: 0.5050 loss_val: 0.6911 acc_val: 0.5440 time: 0.0041s\n",
      "Epoch: 0100 loss_train: 0.6928 acc_train: 0.5410 loss_val: 0.6908 acc_val: 0.5440 time: 0.0038s\n",
      "Epoch: 0110 loss_train: 0.6952 acc_train: 0.5450 loss_val: 0.6908 acc_val: 0.5445 time: 0.0036s\n",
      "Epoch: 0120 loss_train: 0.6877 acc_train: 0.5670 loss_val: 0.6907 acc_val: 0.5445 time: 0.0034s\n",
      "Epoch: 0130 loss_train: 0.6991 acc_train: 0.5380 loss_val: 0.6907 acc_val: 0.5440 time: 0.0032s\n",
      "Epoch: 0140 loss_train: 0.6846 acc_train: 0.5570 loss_val: 0.6908 acc_val: 0.5455 time: 0.0031s\n",
      "Epoch: 0150 loss_train: 0.6879 acc_train: 0.5560 loss_val: 0.6909 acc_val: 0.5440 time: 0.0032s\n",
      "Epoch: 0160 loss_train: 0.6900 acc_train: 0.5500 loss_val: 0.6909 acc_val: 0.5435 time: 0.0032s\n",
      "Epoch: 0170 loss_train: 0.6920 acc_train: 0.5220 loss_val: 0.6908 acc_val: 0.5430 time: 0.0033s\n",
      "Epoch: 0180 loss_train: 0.6935 acc_train: 0.5610 loss_val: 0.6909 acc_val: 0.5425 time: 0.0034s\n",
      "Epoch: 0190 loss_train: 0.6957 acc_train: 0.5420 loss_val: 0.6910 acc_val: 0.5420 time: 0.0032s\n",
      "Epoch: 0200 loss_train: 0.6993 acc_train: 0.5360 loss_val: 0.6911 acc_val: 0.5430 time: 0.0033s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 0.7485s\n",
      "Test set results: loss= 0.6914 accuracy= 0.5473\n"
     ]
    }
   ],
   "source": [
    "train_test(A, X, y, idx_train, idx_val, idx_test,\n",
    "    no_cuda = False,\n",
    "    seed = 40,\n",
    "    epochs = 200,\n",
    "    learning_rate = 0.0001,\n",
    "    weight_decay = 5e-4,\n",
    "    hidden_units = 256,\n",
    "    dropout = 0.5,\n",
    "    type = \"FCN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCN (features and ad-hoc graph variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading musae_ENGB_ dataset...\n",
      "Graph Info:\n",
      " Name: G\n",
      "Type: Graph\n",
      "Number of nodes: 7126\n",
      "Number of edges: 35324\n",
      "Average degree:   9.9141\n",
      "Shape of A:  torch.Size([7126, 7126])\n",
      "\n",
      "Shape of X:  torch.Size([7126, 5])\n",
      "\n",
      "Adjacency Matrix (A):\n",
      " tensor([[0.1250, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0500, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.2500, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0476, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3333]])\n",
      "\n",
      "Node Features Matrix (X):\n",
      " tensor([[-0.0937, -0.0620, -0.2387, -0.1313,  0.7731],\n",
      "        [ 0.1469, -0.0640, -0.2387,  0.4095,  1.5530],\n",
      "        [-1.5768, -0.0495, -0.2387, -0.0412,  0.2745],\n",
      "        ...,\n",
      "        [-0.1517, -0.0639, -0.2387, -0.3116, -0.5563],\n",
      "        [ 0.7370, -0.0631, -0.2387,  0.4546,  0.9533],\n",
      "        [ 0.3846, -0.0640, -0.2387, -0.3567, -0.9963]])\n"
     ]
    }
   ],
   "source": [
    "A1, X1, y1, idx_train, idx_val, idx_test = load_data(\"../data/twitch/\", \"musae_ENGB_\", 1000, 2000, 3000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0010 loss_train: 0.7009 acc_train: 0.5470 loss_val: 0.6907 acc_val: 0.5460 time: 0.0030s\n",
      "Epoch: 0020 loss_train: 0.6965 acc_train: 0.5350 loss_val: 0.6890 acc_val: 0.5450 time: 0.0030s\n",
      "Epoch: 0030 loss_train: 0.6983 acc_train: 0.5230 loss_val: 0.6881 acc_val: 0.5470 time: 0.0030s\n",
      "Epoch: 0040 loss_train: 0.6939 acc_train: 0.5580 loss_val: 0.6875 acc_val: 0.5430 time: 0.0028s\n",
      "Epoch: 0050 loss_train: 0.6963 acc_train: 0.5240 loss_val: 0.6872 acc_val: 0.5465 time: 0.0030s\n",
      "Epoch: 0060 loss_train: 0.6926 acc_train: 0.5410 loss_val: 0.6869 acc_val: 0.5520 time: 0.0028s\n",
      "Epoch: 0070 loss_train: 0.6911 acc_train: 0.5490 loss_val: 0.6866 acc_val: 0.5530 time: 0.0028s\n",
      "Epoch: 0080 loss_train: 0.6855 acc_train: 0.5370 loss_val: 0.6864 acc_val: 0.5500 time: 0.0030s\n",
      "Epoch: 0090 loss_train: 0.6959 acc_train: 0.5550 loss_val: 0.6862 acc_val: 0.5505 time: 0.0029s\n",
      "Epoch: 0100 loss_train: 0.6902 acc_train: 0.5450 loss_val: 0.6860 acc_val: 0.5480 time: 0.0028s\n",
      "Epoch: 0110 loss_train: 0.6841 acc_train: 0.5590 loss_val: 0.6858 acc_val: 0.5470 time: 0.0028s\n",
      "Epoch: 0120 loss_train: 0.6901 acc_train: 0.5440 loss_val: 0.6857 acc_val: 0.5460 time: 0.0027s\n",
      "Epoch: 0130 loss_train: 0.6910 acc_train: 0.5490 loss_val: 0.6855 acc_val: 0.5435 time: 0.0026s\n",
      "Epoch: 0140 loss_train: 0.6901 acc_train: 0.5490 loss_val: 0.6854 acc_val: 0.5450 time: 0.0027s\n",
      "Epoch: 0150 loss_train: 0.6879 acc_train: 0.5670 loss_val: 0.6853 acc_val: 0.5455 time: 0.0026s\n",
      "Epoch: 0160 loss_train: 0.6867 acc_train: 0.5540 loss_val: 0.6852 acc_val: 0.5450 time: 0.0026s\n",
      "Epoch: 0170 loss_train: 0.6794 acc_train: 0.5740 loss_val: 0.6851 acc_val: 0.5460 time: 0.0029s\n",
      "Epoch: 0180 loss_train: 0.6931 acc_train: 0.5370 loss_val: 0.6851 acc_val: 0.5460 time: 0.0028s\n",
      "Epoch: 0190 loss_train: 0.6886 acc_train: 0.5620 loss_val: 0.6850 acc_val: 0.5455 time: 0.0044s\n",
      "Epoch: 0200 loss_train: 0.6785 acc_train: 0.5890 loss_val: 0.6849 acc_val: 0.5475 time: 0.0040s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 0.6022s\n",
      "Test set results: loss= 0.6834 accuracy= 0.5573\n"
     ]
    }
   ],
   "source": [
    "train_test(A1, X1, y1, idx_train, idx_val, idx_test,\n",
    "    no_cuda = False,\n",
    "    seed = 40,\n",
    "    epochs = 200,\n",
    "    learning_rate = 0.0001,\n",
    "    weight_decay = 5e-4,\n",
    "    hidden_units = 256,\n",
    "    dropout = 0.5,\n",
    "    type = \"FCN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# node2vec (graph only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, workers=4)\n",
    "\n",
    " Embed nodes\n",
    "\n",
    "mod = node2vec.fit(window=10, min_count=1, batch_words=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results \n",
    "\n",
    "Epoch: 0190 loss_train: 0.6387 acc_train: 0.6500 loss_val: 0.7089 acc_val: 0.5180 time: 0.0031s\n",
    "\n",
    "Epoch: 0200 loss_train: 0.6372 acc_train: 0.6580 loss_val: 0.7102 acc_val: 0.5220 time: 0.0030s\n",
    "\n",
    "Optimization Finished!\n",
    "Total time elapsed: 0.6735s\n",
    "Test set results: loss= 0.7037 accuracy= 0.5180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# node2vec (graph and features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch: 0190 loss_train: 0.6347 acc_train: 0.6420 loss_val: 0.7088 acc_val: 0.5095 time: 0.0045s\n",
    "\n",
    "Epoch: 0200 loss_train: 0.6377 acc_train: 0.6420 loss_val: 0.7098 acc_val: 0.5095 time: 0.0030s\n",
    "\n",
    "Optimization Finished!\n",
    "Total time elapsed: 0.6197s\n",
    "Test set results: loss= 0.7161 accuracy= 0.5093"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN (nodes and features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0010 loss_train: 0.6941 acc_train: 0.4540 loss_val: 0.6938 acc_val: 0.4560 time: 0.0495s\n",
      "Epoch: 0020 loss_train: 0.6920 acc_train: 0.5460 loss_val: 0.6919 acc_val: 0.5440 time: 0.0479s\n",
      "Epoch: 0030 loss_train: 0.6905 acc_train: 0.5460 loss_val: 0.6905 acc_val: 0.5440 time: 0.0488s\n",
      "Epoch: 0040 loss_train: 0.6894 acc_train: 0.5460 loss_val: 0.6896 acc_val: 0.5440 time: 0.0490s\n",
      "Epoch: 0050 loss_train: 0.6890 acc_train: 0.5460 loss_val: 0.6892 acc_val: 0.5440 time: 0.0486s\n",
      "Epoch: 0060 loss_train: 0.6888 acc_train: 0.5460 loss_val: 0.6891 acc_val: 0.5440 time: 0.0494s\n",
      "Epoch: 0070 loss_train: 0.6888 acc_train: 0.5460 loss_val: 0.6891 acc_val: 0.5440 time: 0.0486s\n",
      "Epoch: 0080 loss_train: 0.6888 acc_train: 0.5460 loss_val: 0.6891 acc_val: 0.5440 time: 0.0478s\n",
      "Epoch: 0090 loss_train: 0.6888 acc_train: 0.5460 loss_val: 0.6891 acc_val: 0.5440 time: 0.0486s\n",
      "Epoch: 0100 loss_train: 0.6888 acc_train: 0.5460 loss_val: 0.6891 acc_val: 0.5440 time: 0.0482s\n",
      "Epoch: 0110 loss_train: 0.6888 acc_train: 0.5460 loss_val: 0.6891 acc_val: 0.5440 time: 0.0518s\n",
      "Epoch: 0120 loss_train: 0.6888 acc_train: 0.5460 loss_val: 0.6891 acc_val: 0.5440 time: 0.0488s\n",
      "Epoch: 0130 loss_train: 0.6888 acc_train: 0.5460 loss_val: 0.6891 acc_val: 0.5440 time: 0.0489s\n",
      "Epoch: 0140 loss_train: 0.6887 acc_train: 0.5460 loss_val: 0.6891 acc_val: 0.5440 time: 0.0495s\n",
      "Epoch: 0150 loss_train: 0.6887 acc_train: 0.5460 loss_val: 0.6891 acc_val: 0.5440 time: 0.0495s\n",
      "Epoch: 0160 loss_train: 0.6887 acc_train: 0.5460 loss_val: 0.6890 acc_val: 0.5440 time: 0.0489s\n",
      "Epoch: 0170 loss_train: 0.6887 acc_train: 0.5460 loss_val: 0.6890 acc_val: 0.5440 time: 0.0489s\n",
      "Epoch: 0180 loss_train: 0.6887 acc_train: 0.5460 loss_val: 0.6890 acc_val: 0.5440 time: 0.0499s\n",
      "Epoch: 0190 loss_train: 0.6887 acc_train: 0.5460 loss_val: 0.6890 acc_val: 0.5440 time: 0.0490s\n",
      "Epoch: 0200 loss_train: 0.6886 acc_train: 0.5460 loss_val: 0.6890 acc_val: 0.5440 time: 0.0515s\n",
      "Epoch: 0210 loss_train: 0.6887 acc_train: 0.5460 loss_val: 0.6889 acc_val: 0.5440 time: 0.0490s\n",
      "Epoch: 0220 loss_train: 0.6885 acc_train: 0.5460 loss_val: 0.6889 acc_val: 0.5440 time: 0.0517s\n",
      "Epoch: 0230 loss_train: 0.6885 acc_train: 0.5460 loss_val: 0.6888 acc_val: 0.5440 time: 0.0503s\n",
      "Epoch: 0240 loss_train: 0.6884 acc_train: 0.5460 loss_val: 0.6888 acc_val: 0.5440 time: 0.0515s\n",
      "Epoch: 0250 loss_train: 0.6884 acc_train: 0.5460 loss_val: 0.6887 acc_val: 0.5440 time: 0.0497s\n",
      "Epoch: 0260 loss_train: 0.6883 acc_train: 0.5460 loss_val: 0.6886 acc_val: 0.5440 time: 0.0492s\n",
      "Epoch: 0270 loss_train: 0.6882 acc_train: 0.5460 loss_val: 0.6885 acc_val: 0.5440 time: 0.0490s\n",
      "Epoch: 0280 loss_train: 0.6880 acc_train: 0.5460 loss_val: 0.6883 acc_val: 0.5440 time: 0.0493s\n",
      "Epoch: 0290 loss_train: 0.6879 acc_train: 0.5460 loss_val: 0.6881 acc_val: 0.5440 time: 0.0484s\n",
      "Epoch: 0300 loss_train: 0.6876 acc_train: 0.5460 loss_val: 0.6877 acc_val: 0.5440 time: 0.0517s\n",
      "Epoch: 0310 loss_train: 0.6873 acc_train: 0.5460 loss_val: 0.6873 acc_val: 0.5440 time: 0.0515s\n",
      "Epoch: 0320 loss_train: 0.6866 acc_train: 0.5460 loss_val: 0.6866 acc_val: 0.5440 time: 0.0517s\n",
      "Epoch: 0330 loss_train: 0.6858 acc_train: 0.5460 loss_val: 0.6858 acc_val: 0.5440 time: 0.0492s\n",
      "Epoch: 0340 loss_train: 0.6842 acc_train: 0.5440 loss_val: 0.6847 acc_val: 0.5440 time: 0.0488s\n",
      "Epoch: 0350 loss_train: 0.6820 acc_train: 0.5510 loss_val: 0.6838 acc_val: 0.5555 time: 0.0488s\n",
      "Epoch: 0360 loss_train: 0.6812 acc_train: 0.5630 loss_val: 0.6842 acc_val: 0.5550 time: 0.0494s\n",
      "Epoch: 0370 loss_train: 0.6798 acc_train: 0.5740 loss_val: 0.6859 acc_val: 0.5570 time: 0.0504s\n",
      "Epoch: 0380 loss_train: 0.6777 acc_train: 0.5750 loss_val: 0.6862 acc_val: 0.5545 time: 0.0458s\n",
      "Epoch: 0390 loss_train: 0.6769 acc_train: 0.5760 loss_val: 0.6860 acc_val: 0.5560 time: 0.0489s\n",
      "Epoch: 0400 loss_train: 0.6773 acc_train: 0.5800 loss_val: 0.6858 acc_val: 0.5545 time: 0.0496s\n",
      "Epoch: 0410 loss_train: 0.6772 acc_train: 0.5700 loss_val: 0.6861 acc_val: 0.5610 time: 0.0490s\n",
      "Epoch: 0420 loss_train: 0.6760 acc_train: 0.5780 loss_val: 0.6866 acc_val: 0.5505 time: 0.0488s\n",
      "Epoch: 0430 loss_train: 0.6756 acc_train: 0.5790 loss_val: 0.6867 acc_val: 0.5495 time: 0.0486s\n",
      "Epoch: 0440 loss_train: 0.6735 acc_train: 0.5850 loss_val: 0.6866 acc_val: 0.5585 time: 0.0485s\n",
      "Epoch: 0450 loss_train: 0.6742 acc_train: 0.5770 loss_val: 0.6869 acc_val: 0.5475 time: 0.0488s\n",
      "Epoch: 0460 loss_train: 0.6735 acc_train: 0.5760 loss_val: 0.6875 acc_val: 0.5525 time: 0.0497s\n",
      "Epoch: 0470 loss_train: 0.6737 acc_train: 0.5820 loss_val: 0.6877 acc_val: 0.5535 time: 0.0484s\n",
      "Epoch: 0480 loss_train: 0.6720 acc_train: 0.5900 loss_val: 0.6878 acc_val: 0.5645 time: 0.0496s\n",
      "Epoch: 0490 loss_train: 0.6699 acc_train: 0.5940 loss_val: 0.6876 acc_val: 0.5655 time: 0.0453s\n",
      "Epoch: 0500 loss_train: 0.6699 acc_train: 0.5810 loss_val: 0.6884 acc_val: 0.5590 time: 0.0486s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 17.0368s\n",
      "Test set results: loss= 0.6843 accuracy= 0.5570\n"
     ]
    }
   ],
   "source": [
    "train_test(A, X, y, idx_train, idx_val, idx_test,\n",
    "    no_cuda = False,\n",
    "    seed = 40,\n",
    "    epochs = 500,\n",
    "    learning_rate = 0.0001,\n",
    "    weight_decay = 5e-4,\n",
    "    hidden_units = 256,\n",
    "    dropout = 0.5,\n",
    "    type = \"GCN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion Questions\n",
    "\n",
    "This node classification task is transductive as not all streamers are classified as Mature or not. Streamers aren't required to say if they use explicit language or not so it would make sense to look at the fixed network to figure out which streamers are mature are not using node classification.\n",
    "\n",
    "The Train-Test split can be done on the feature level then so that the full network can still be inputted into the model since there are essentially unlabled gaps in the network that we would want to classify.\n",
    "\n",
    "*Summarize how each ML approach handles inductive graph learning (adding new nodes and edges at test-time). What computation has to occur at test-time?*\n",
    "\n",
    "FCN(only features): This does fine with inductive graph learning because there is no link between the data points.\n",
    "\n",
    "FCN (features and ad-hoc graph variables): This also does fine since there are features to carry predictions even if new data points don't have ad-hoc summarizations. I think at test time this graph input has to be imputed.\n",
    "\n",
    "All graph inputted approaches: Need to use something like GraphSAGE that generates embeddings by \"sampling and aggregating features from a nodeâ€™s local neighborhood\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
